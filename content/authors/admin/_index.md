---
organizations:
  - name: Bar Ilan University
    url: ""
superuser: true
authors:
  - admin
title:
role: Computer Science PhD Student
avatar_filename: avatar.jpeg
bio: ""
social:
  - icon: twitter
    icon_pack: fab
    link: https://twitter.com/RoyiRassin
  - icon: google-scholar
    icon_pack: ai
    link: https://scholar.google.com/citations?hl=en&user=YNarSkMAAAAJ
  - icon: github
    icon_pack: fab
    link: https://github.com/RoyiRa
  - link: https://www.linkedin.com/in/royi-rassin-4b8085163/
    icon: linkedin
    icon_pack: fab
education:
  courses:
    - course: PhD in Computer Science (in-progress)
      institution: Bar Ilan University
      year: ""
    - course: MSc in Computer Science
      institution: Bar Ilan University
      year: ""    
email: ""
user_groups:
  - Researchers
  - Visitors
---
Hello! I am a second year PhD student in the [Natural Language Processing Lab](https://biu-nlp.github.io/) at Bar-Ilan University, supervised by [prof. Yoav Goldberg](https://u.cs.biu.ac.il/~yogo/). Iâ€™m working on bridging the gap between modalities, and then revealing the capabilities multimodal models have when considering more than one modality at a time. Currently, my research is focused on image-text alignment and controlled generation (what kind of changes do we need to make to generate images that are more faithful to the input prompt?). I find it particularly interesting to work on better architectures, which can be faster (not attention based?) or simply more scalable than current ones.

Previously, I obtained my Masters in Computer Science, and was jointly supervised by Yoav Goldberg and Reut Tsarfaty. Then, I was driven by fascination with underspecified language. Why do models often misinterpret ambiguous language, and we don't? How can we make implicit information more explicit? My thesis work aimed to answer these questions in the context of verbal omissions in coordination structures. As a fun detour, I stumbled upon intriguing behavior by DALL-E when fed with ambiguous language, where it depicts multiple interpretations in a single image, instead of settling on one. We detailed this behavior in a short [paper](https://arxiv.org/abs/2210.10606).

My CV is available [here](cv/cv.pdf).
